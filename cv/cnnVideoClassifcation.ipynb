{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a42a09",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN과 RNN을 이용하여 action classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7477d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 형식에 맞게 파일 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d59f60a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainlist, testlist 이동\n",
    "cnt = 0\n",
    "trainFile_list = []\n",
    "testFile_list = []\n",
    "with open(\"../dataset/ucfTrainTestlist/trainlist02.txt\") as f:\n",
    "    for a in f:\n",
    "        trainFile_list.append(a.split())\n",
    "with open(\"../dataset/ucfTrainTestlist/testlist02.txt\") as f:\n",
    "    for a in f:\n",
    "        testFile_list.append(a.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fbada6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9586"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainFile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69675065",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3734"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testFile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6aa5fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# label값 가져오기\n",
    "label_dict = {}\n",
    "with open(\"../dataset/ucfTrainTestlist/classInd.txt\") as f:\n",
    "    for a in f:\n",
    "        data = a.split()\n",
    "        label_dict[data[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1f85c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test,train,video 저장경로 설정\n",
    "import os\n",
    "test_path = \"../dataset/ucfTrainTest/test/\"\n",
    "train_path = \"../dataset/ucfTrainTest/train/\"\n",
    "videoPath = \"../dataset/UCF-101/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff483e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 파일 이동\n",
    "for fileName in [x[0] for x in trainFile_list]:\n",
    "    os.rename(videoPath+fileName, train_path+fileName)\n",
    "for fileName in [x[0] for x in testFile_list]:\n",
    "    os.rename(videoPath+fileName, test_path+fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b4b70e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PushUps', 'ParallelBars', 'BlowingCandles', 'Biking', 'Skiing', 'Skijet', 'TrampolineJumping', 'Swing', 'RopeClimbing', 'Bowling', 'Basketball', 'YoYo', 'CricketShot', 'BoxingSpeedBag', 'MilitaryParade', 'PlayingTabla', 'IceDancing', 'HammerThrow', 'FieldHockeyPenalty', 'BenchPress', 'JumpingJack', 'SumoWrestling', 'Mixing', 'JumpRope', 'Fencing', 'PlayingCello', 'SalsaSpin', 'Punch', 'WritingOnBoard', 'SoccerJuggling', 'HighJump', 'CuttingInKitchen', 'PommelHorse', 'Surfing', 'BlowDryHair', 'Rafting', 'BreastStroke', 'Diving', 'HeadMassage', 'WalkingWithDog', 'Archery', 'PlayingSitar', 'SkyDiving', 'FrontCrawl', 'Billiards', 'RockClimbingIndoor', 'SkateBoarding', 'HandstandWalking', 'Kayaking', 'PlayingGuitar', 'VolleyballSpiking', 'Typing', 'PlayingPiano', 'CliffDiving', 'UnevenBars', 'Shotput', 'Knitting', 'ApplyEyeMakeup', 'BandMarching', 'GolfSwing', 'BaseballPitch', 'TennisSwing', 'ThrowDiscus', 'CleanAndJerk', 'ShavingBeard', 'JugglingBalls', 'BalanceBeam', 'WallPushups', 'Hammering', 'HandstandPushups', 'PlayingViolin', 'BasketballDunk', 'Rowing', 'MoppingFloor', 'PizzaTossing', 'BabyCrawling', 'PlayingDhol', 'HorseRiding', 'FloorGymnastics', 'ApplyLipstick', 'PoleVault', 'CricketBowling', 'SoccerPenalty', 'HorseRace', 'Lunges', 'HulaHoop', 'LongJump', 'FrisbeeCatch', 'BrushingTeeth', 'PlayingFlute', 'StillRings', 'Nunchucks', 'Haircut', 'TableTennisShot', 'JavelinThrow', 'PlayingDaf', 'TaiChi', 'BodyWeightSquats', 'BoxingPunchingBag', 'Drumming', 'PullUps']\n"
     ]
    }
   ],
   "source": [
    "#라벨 값 가져오기\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir('../dataset/ucfTrainTest/train/')\n",
    "\n",
    "label_types = os.listdir('../dataset/ucfTrainTest/train/')\n",
    "print (label_types)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f06c4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 훈련 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e00542",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       tag                                         video_name\n",
      "0  PushUps  ../dataset/ucfTrainTest/train//PushUps/v_PushU...\n",
      "1  PushUps  ../dataset/ucfTrainTest/train//PushUps/v_PushU...\n",
      "2  PushUps  ../dataset/ucfTrainTest/train//PushUps/v_PushU...\n",
      "3  PushUps  ../dataset/ucfTrainTest/train//PushUps/v_PushU...\n",
      "4  PushUps  ../dataset/ucfTrainTest/train//PushUps/v_PushU...\n",
      "          tag                                         video_name\n",
      "9581  PullUps  ../dataset/ucfTrainTest/train//PullUps/v_PullU...\n",
      "9582  PullUps  ../dataset/ucfTrainTest/train//PullUps/v_PullU...\n",
      "9583  PullUps  ../dataset/ucfTrainTest/train//PullUps/v_PullU...\n",
      "9584  PullUps  ../dataset/ucfTrainTest/train//PullUps/v_PullU...\n",
      "9585  PullUps  ../dataset/ucfTrainTest/train//PullUps/v_PullU...\n"
     ]
    }
   ],
   "source": [
    "rooms = []\n",
    "# 모든 파일 이름 가져오기\n",
    "for item in dataset_path:\n",
    "    all_rooms = os.listdir(train_path + '/' +item)\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item, str(train_path + '/' +item) + '/' + room))\n",
    "\n",
    "# 데이터 프레임 생성     \n",
    "train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
    "print(train_df.head())\n",
    "print(train_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ac79ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# csv 파일 생성\n",
    "df = train_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0897c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 훈련 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413b31f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PushUps', 'ParallelBars', 'BlowingCandles', 'Biking', 'Skiing', 'Skijet', 'TrampolineJumping', 'Swing', 'RopeClimbing', 'Bowling', 'Basketball', 'YoYo', 'CricketShot', 'BoxingSpeedBag', 'MilitaryParade', 'PlayingTabla', 'IceDancing', 'HammerThrow', 'FieldHockeyPenalty', 'BenchPress', 'JumpingJack', 'SumoWrestling', 'Mixing', 'JumpRope', 'Fencing', 'PlayingCello', 'SalsaSpin', 'Punch', 'WritingOnBoard', 'SoccerJuggling', 'HighJump', 'CuttingInKitchen', 'PommelHorse', 'Surfing', 'BlowDryHair', 'Rafting', 'BreastStroke', 'Diving', 'HeadMassage', 'WalkingWithDog', 'Archery', 'PlayingSitar', 'SkyDiving', 'FrontCrawl', 'Billiards', 'RockClimbingIndoor', 'SkateBoarding', 'HandstandWalking', 'Kayaking', 'PlayingGuitar', 'VolleyballSpiking', 'Typing', 'PlayingPiano', 'CliffDiving', 'UnevenBars', 'Shotput', 'Knitting', 'ApplyEyeMakeup', 'BandMarching', 'GolfSwing', 'BaseballPitch', 'TennisSwing', 'ThrowDiscus', 'CleanAndJerk', 'ShavingBeard', 'JugglingBalls', 'BalanceBeam', 'WallPushups', 'Hammering', 'HandstandPushups', 'PlayingViolin', 'BasketballDunk', 'Rowing', 'MoppingFloor', 'PizzaTossing', 'BabyCrawling', 'PlayingDhol', 'HorseRiding', 'FloorGymnastics', 'ApplyLipstick', 'PoleVault', 'CricketBowling', 'SoccerPenalty', 'HorseRace', 'Lunges', 'HulaHoop', 'LongJump', 'FrisbeeCatch', 'BrushingTeeth', 'PlayingFlute', 'StillRings', 'Nunchucks', 'Haircut', 'TableTennisShot', 'JavelinThrow', 'PlayingDaf', 'TaiChi', 'BodyWeightSquats', 'BoxingPunchingBag', 'Drumming', 'PullUps']\n",
      "Types of activities found:  101\n",
      "       tag                                         video_name\n",
      "0  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "1  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "2  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "3  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "4  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "        tag                                         video_name\n",
      "23  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "24  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "25  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "26  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n",
      "27  PullUps  ../dataset/ucfTrainTest/test//PullUps/v_PullUp...\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.listdir(test_path)\n",
    "print(dataset_path)\n",
    "\n",
    "room_types = os.listdir(test_path)\n",
    "print(\"Types of activities found: \", len(dataset_path))\n",
    "\n",
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    "# 모든 파일 이름 가져오기\n",
    "    all_rooms = os.listdir(test_path + '/' +item)\n",
    "\n",
    "\n",
    "for room in all_rooms:\n",
    "    rooms.append((item, str(test_path + '/' +item) + '/' + room))\n",
    "    \n",
    "# Build a dataframe        \n",
    "test_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "\n",
    "df = test_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45fb7c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-79fqn2pb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-79fqn2pb\n",
      "  Resolved https://github.com/tensorflow/docs to commit 245c95ded9f7c58b254f5982451538187899d1c8\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: astor in /nlp/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: absl-py in /nlp/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (0.15.0)\n",
      "Requirement already satisfied: jinja2 in /nlp/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.12.0 in /nlp/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (3.19.4)\n",
      "Requirement already satisfied: pyyaml in /nlp/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
      "Requirement already satisfied: six in /nlp/lib/python3.8/site-packages (from absl-py->tensorflow-docs==0.0.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /nlp/lib/python3.8/site-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "918d9338",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 04:33:00.356598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4fed40c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf44bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b716cfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 9586\n",
      "Total videos for testing: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>../dataset/ucfTrainTest/train//Skiing/v_Skiing...</td>\n",
       "      <td>Skiing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>../dataset/ucfTrainTest/train//Basketball/v_Ba...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>4707</td>\n",
       "      <td>../dataset/ucfTrainTest/train//PlayingGuitar/v...</td>\n",
       "      <td>PlayingGuitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>1079</td>\n",
       "      <td>../dataset/ucfTrainTest/train//CricketShot/v_C...</td>\n",
       "      <td>CricketShot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>3229</td>\n",
       "      <td>../dataset/ucfTrainTest/train//BlowDryHair/v_B...</td>\n",
       "      <td>BlowDryHair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>7433</td>\n",
       "      <td>../dataset/ucfTrainTest/train//FloorGymnastics...</td>\n",
       "      <td>FloorGymnastics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>3273</td>\n",
       "      <td>../dataset/ucfTrainTest/train//BlowDryHair/v_B...</td>\n",
       "      <td>BlowDryHair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>../dataset/ucfTrainTest/train//BlowingCandles/...</td>\n",
       "      <td>BlowingCandles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>1114</td>\n",
       "      <td>../dataset/ucfTrainTest/train//CricketShot/v_C...</td>\n",
       "      <td>CricketShot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1026</td>\n",
       "      <td>../dataset/ucfTrainTest/train//YoYo/v_YoYo_g22...</td>\n",
       "      <td>YoYo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                         video_name  \\\n",
       "392          392  ../dataset/ucfTrainTest/train//Skiing/v_Skiing...   \n",
       "923          923  ../dataset/ucfTrainTest/train//Basketball/v_Ba...   \n",
       "4707        4707  ../dataset/ucfTrainTest/train//PlayingGuitar/v...   \n",
       "1079        1079  ../dataset/ucfTrainTest/train//CricketShot/v_C...   \n",
       "3229        3229  ../dataset/ucfTrainTest/train//BlowDryHair/v_B...   \n",
       "7433        7433  ../dataset/ucfTrainTest/train//FloorGymnastics...   \n",
       "3273        3273  ../dataset/ucfTrainTest/train//BlowDryHair/v_B...   \n",
       "163          163  ../dataset/ucfTrainTest/train//BlowingCandles/...   \n",
       "1114        1114  ../dataset/ucfTrainTest/train//CricketShot/v_C...   \n",
       "1026        1026  ../dataset/ucfTrainTest/train//YoYo/v_YoYo_g22...   \n",
       "\n",
       "                  tag  \n",
       "392            Skiing  \n",
       "923        Basketball  \n",
       "4707    PlayingGuitar  \n",
       "1079      CricketShot  \n",
       "3229      BlowDryHair  \n",
       "7433  FloorGymnastics  \n",
       "3273      BlowDryHair  \n",
       "163    BlowingCandles  \n",
       "1114      CricketShot  \n",
       "1026             YoYo  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c182a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd68b72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243c6ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 특징 추출(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "388c0afe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ca626",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Label Encoding\n",
    "문자를 정수로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4df9dfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801339d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam', 'BandMarching', 'BaseballPitch', 'Basketball', 'BasketballDunk', 'BenchPress', 'Biking', 'Billiards', 'BlowDryHair', 'BlowingCandles', 'BodyWeightSquats', 'Bowling', 'BoxingPunchingBag', 'BoxingSpeedBag', 'BreastStroke', 'BrushingTeeth', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'CuttingInKitchen', 'Diving', 'Drumming', 'Fencing', 'FieldHockeyPenalty', 'FloorGymnastics', 'FrisbeeCatch', 'FrontCrawl', 'GolfSwing', 'Haircut', 'HammerThrow', 'Hammering', 'HandstandPushups', 'HandstandWalking', 'HeadMassage', 'HighJump', 'HorseRace', 'HorseRiding', 'HulaHoop', 'IceDancing', 'JavelinThrow', 'JugglingBalls', 'JumpRope', 'JumpingJack', 'Kayaking', 'Knitting', 'LongJump', 'Lunges', 'MilitaryParade', 'Mixing', 'MoppingFloor', 'Nunchucks', 'ParallelBars', 'PizzaTossing', 'PlayingCello', 'PlayingDaf', 'PlayingDhol', 'PlayingFlute', 'PlayingGuitar', 'PlayingPiano', 'PlayingSitar', 'PlayingTabla', 'PlayingViolin', 'PoleVault', 'PommelHorse', 'PullUps', 'Punch', 'PushUps', 'Rafting', 'RockClimbingIndoor', 'RopeClimbing', 'Rowing', 'SalsaSpin', 'ShavingBeard', 'Shotput', 'SkateBoarding', 'Skiing', 'Skijet', 'SkyDiving', 'SoccerJuggling', 'SoccerPenalty', 'StillRings', 'SumoWrestling', 'Surfing', 'Swing', 'TableTennisShot', 'TaiChi', 'TennisSwing', 'ThrowDiscus', 'TrampolineJumping', 'Typing', 'UnevenBars', 'VolleyballSpiking', 'WalkingWithDog', 'WallPushups', 'WritingOnBoard', 'YoYo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[72],\n",
       "       [72],\n",
       "       [72],\n",
       "       ...,\n",
       "       [70],\n",
       "       [70],\n",
       "       [70]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "label_processor = keras.layers.experimental.preprocessing.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76216366",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11befa62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (9586, 20, 2048)\n",
      "Frame masks in train set: (9586, 20)\n",
      "train_labels in train set: (9586, 1)\n",
      "test_labels in train set: (28, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    \n",
    "    ## 리스트에 모든 label 저장\n",
    "    labels = df[\"tag\"].values\n",
    "    \n",
    "    #레이블을 정수로 인코딩\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # \"'frame_filename'과 'frame_filename'은 시퀀스 모델에 공급할 것입니다.\n",
    "    # \"frame_filename\"은 타임 스텝이 다음과 같음을 나타내는 부울을 여러 개 포함합니다.\n",
    "    # 패딩으로 가면을 썼는지 안 썼는지\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
    "\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # 모든 프레임을 수집하고 배치를 추가합니다.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "        \n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # 동영상을 각각 이미지를 특징 추출\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train_labels in train set: {train_labels.shape}\")\n",
    "\n",
    "print(f\"test_labels in train set: {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e0827",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 모델 생성\n",
    "GRU 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7382f3c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 04:37:47.992869: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1099366400 exceeds 10% of free system memory.\n",
      "2022-06-09 04:37:50.020442: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 04:37:55.126426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-06-09 04:37:56.719364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - ETA: 0s - loss: 4.6072 - accuracy: 0.0113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 04:40:24.529533: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 471203840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 169s 767ms/step - loss: 4.6071 - accuracy: 0.0113 - val_loss: 4.7952 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.79520, saving model to ./tmp/video_classifier\n",
      "Epoch 2/30\n",
      "210/210 [==============================] - 155s 738ms/step - loss: 4.5422 - accuracy: 0.0134 - val_loss: 4.9612 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.79520\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 179s 853ms/step - loss: 4.4912 - accuracy: 0.0200 - val_loss: 5.1203 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.79520\n",
      "Epoch 4/30\n",
      "210/210 [==============================] - 152s 723ms/step - loss: 4.4524 - accuracy: 0.0176 - val_loss: 5.2724 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.79520\n",
      "Epoch 5/30\n",
      "210/210 [==============================] - 154s 733ms/step - loss: 4.4221 - accuracy: 0.0151 - val_loss: 5.4176 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.79520\n",
      "Epoch 6/30\n",
      "210/210 [==============================] - 155s 737ms/step - loss: 4.3972 - accuracy: 0.0155 - val_loss: 5.5565 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.79520\n",
      "Epoch 7/30\n",
      "210/210 [==============================] - 152s 726ms/step - loss: 4.3755 - accuracy: 0.0175 - val_loss: 5.6895 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.79520\n",
      "Epoch 8/30\n",
      "210/210 [==============================] - 151s 720ms/step - loss: 4.3602 - accuracy: 0.0160 - val_loss: 5.8174 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.79520\n",
      "Epoch 9/30\n",
      "210/210 [==============================] - 153s 729ms/step - loss: 4.3458 - accuracy: 0.0166 - val_loss: 5.9405 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.79520\n",
      "Epoch 10/30\n",
      "210/210 [==============================] - 161s 768ms/step - loss: 4.3346 - accuracy: 0.0197 - val_loss: 6.0593 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.79520\n",
      "Epoch 11/30\n",
      "210/210 [==============================] - 164s 782ms/step - loss: 4.3281 - accuracy: 0.0170 - val_loss: 6.1745 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.79520\n",
      "Epoch 12/30\n",
      "210/210 [==============================] - 159s 756ms/step - loss: 4.3188 - accuracy: 0.0132 - val_loss: 6.2865 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.79520\n",
      "Epoch 13/30\n",
      "210/210 [==============================] - 152s 723ms/step - loss: 4.3102 - accuracy: 0.0186 - val_loss: 6.3954 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.79520\n",
      "Epoch 14/30\n",
      "210/210 [==============================] - 153s 731ms/step - loss: 4.3039 - accuracy: 0.0173 - val_loss: 6.5017 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.79520\n",
      "Epoch 15/30\n",
      "210/210 [==============================] - 151s 719ms/step - loss: 4.2993 - accuracy: 0.0189 - val_loss: 6.6058 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.79520\n",
      "Epoch 16/30\n",
      "210/210 [==============================] - 154s 735ms/step - loss: 4.2925 - accuracy: 0.0180 - val_loss: 6.7078 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.79520\n",
      "Epoch 17/30\n",
      "210/210 [==============================] - 153s 728ms/step - loss: 4.2878 - accuracy: 0.0156 - val_loss: 6.8079 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.79520\n",
      "Epoch 18/30\n",
      "210/210 [==============================] - 151s 718ms/step - loss: 4.2844 - accuracy: 0.0169 - val_loss: 6.9065 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.79520\n",
      "Epoch 19/30\n",
      "210/210 [==============================] - 155s 737ms/step - loss: 4.2835 - accuracy: 0.0172 - val_loss: 7.0037 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.79520\n",
      "Epoch 20/30\n",
      "210/210 [==============================] - 158s 754ms/step - loss: 4.2803 - accuracy: 0.0124 - val_loss: 7.0996 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.79520\n",
      "Epoch 21/30\n",
      "210/210 [==============================] - 155s 740ms/step - loss: 4.2784 - accuracy: 0.0158 - val_loss: 7.1945 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.79520\n",
      "Epoch 22/30\n",
      "210/210 [==============================] - 153s 729ms/step - loss: 4.2776 - accuracy: 0.0177 - val_loss: 7.2883 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.79520\n",
      "Epoch 23/30\n",
      "210/210 [==============================] - 156s 743ms/step - loss: 4.2730 - accuracy: 0.0194 - val_loss: 7.3814 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.79520\n",
      "Epoch 24/30\n",
      "210/210 [==============================] - 155s 736ms/step - loss: 4.2676 - accuracy: 0.0183 - val_loss: 7.4735 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.79520\n",
      "Epoch 25/30\n",
      "210/210 [==============================] - 156s 744ms/step - loss: 4.2687 - accuracy: 0.0159 - val_loss: 7.5651 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.79520\n",
      "Epoch 26/30\n",
      "210/210 [==============================] - 161s 769ms/step - loss: 4.2625 - accuracy: 0.0191 - val_loss: 7.6560 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.79520\n",
      "Epoch 27/30\n",
      "210/210 [==============================] - 165s 787ms/step - loss: 4.2668 - accuracy: 0.0202 - val_loss: 7.7464 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.79520\n",
      "Epoch 28/30\n",
      "210/210 [==============================] - 168s 801ms/step - loss: 4.2641 - accuracy: 0.0163 - val_loss: 7.8364 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.79520\n",
      "Epoch 29/30\n",
      "210/210 [==============================] - 159s 758ms/step - loss: 4.2643 - accuracy: 0.0146 - val_loss: 7.9260 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.79520\n",
      "Epoch 30/30\n",
      "210/210 [==============================] - 153s 731ms/step - loss: 4.2644 - accuracy: 0.0185 - val_loss: 8.0151 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4.79520\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 4.7962 - accuracy: 0.0000e+00\n",
      "Test accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "def run_experiment():\n",
    "    filepath = \"./tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f1681",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "846a5956",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: ../dataset/ucfTrainTest/test//PullUps/v_PullUps_g11_c04.avi\n",
      "  TennisSwing:  1.08%\n",
      "  WritingOnBoard:  1.08%\n",
      "  ShavingBeard:  1.08%\n",
      "  BenchPress:  1.08%\n",
      "  PlayingCello:  1.08%\n",
      "  PlayingGuitar:  1.07%\n",
      "  CricketShot:  1.07%\n",
      "  Punch:  1.07%\n",
      "  IceDancing:  1.07%\n",
      "  PlayingSitar:  1.07%\n",
      "  Bowling:  1.07%\n",
      "  Diving:  1.07%\n",
      "  BandMarching:  1.07%\n",
      "  BaseballPitch:  1.07%\n",
      "  Archery:  1.07%\n",
      "  HammerThrow:  1.07%\n",
      "  ApplyEyeMakeup:  1.06%\n",
      "  GolfSwing:  1.06%\n",
      "  RockClimbingIndoor:  1.06%\n",
      "  SoccerJuggling:  1.06%\n",
      "  HeadMassage:  1.06%\n",
      "  Hammering:  1.06%\n",
      "  Billiards:  1.06%\n",
      "  Kayaking:  1.06%\n",
      "  Shotput:  1.06%\n",
      "  Basketball:  1.06%\n",
      "  Skiing:  1.06%\n",
      "  Swing:  1.05%\n",
      "  JumpRope:  1.05%\n",
      "  FrontCrawl:  1.05%\n",
      "  Biking:  1.05%\n",
      "  BoxingSpeedBag:  1.05%\n",
      "  CliffDiving:  1.05%\n",
      "  HandstandPushups:  1.05%\n",
      "  BlowDryHair:  1.05%\n",
      "  YoYo:  1.05%\n",
      "  SalsaSpin:  1.05%\n",
      "  MilitaryParade:  1.04%\n",
      "  Surfing:  1.04%\n",
      "  ThrowDiscus:  1.04%\n",
      "  WallPushups:  1.04%\n",
      "  Knitting:  1.04%\n",
      "  Typing:  1.04%\n",
      "  Mixing:  1.04%\n",
      "  JumpingJack:  1.04%\n",
      "  FieldHockeyPenalty:  1.04%\n",
      "  PommelHorse:  1.04%\n",
      "  WalkingWithDog:  1.04%\n",
      "  TrampolineJumping:  1.04%\n",
      "  SumoWrestling:  1.04%\n",
      "  JugglingBalls:  1.04%\n",
      "  HighJump:  1.04%\n",
      "  SkateBoarding:  1.03%\n",
      "  RopeClimbing:  1.03%\n",
      "  HandstandWalking:  1.03%\n",
      "  BlowingCandles:  1.03%\n",
      "  SkyDiving:  1.03%\n",
      "  VolleyballSpiking:  1.03%\n",
      "  BalanceBeam:  1.03%\n",
      "  PlayingTabla:  1.03%\n",
      "  ParallelBars:  1.03%\n",
      "  CuttingInKitchen:  1.03%\n",
      "  Fencing:  1.03%\n",
      "  PlayingPiano:  1.03%\n",
      "  Rafting:  1.02%\n",
      "  CleanAndJerk:  1.02%\n",
      "  PushUps:  1.02%\n",
      "  BreastStroke:  1.02%\n",
      "  Skijet:  1.01%\n",
      "  UnevenBars:  1.01%\n",
      "  PlayingViolin:  0.99%\n",
      "  StillRings:  0.83%\n",
      "  ApplyLipstick:  0.83%\n",
      "  TableTennisShot:  0.83%\n",
      "  BrushingTeeth:  0.83%\n",
      "  BodyWeightSquats:  0.83%\n",
      "  SoccerPenalty:  0.83%\n",
      "  TaiChi:  0.83%\n",
      "  BoxingPunchingBag:  0.83%\n",
      "  BasketballDunk:  0.83%\n",
      "  BabyCrawling:  0.83%\n",
      "  PlayingDaf:  0.83%\n",
      "  CricketBowling:  0.83%\n",
      "  Rowing:  0.83%\n",
      "  Nunchucks:  0.83%\n",
      "  MoppingFloor:  0.83%\n",
      "  PlayingDhol:  0.83%\n",
      "  Lunges:  0.83%\n",
      "  LongJump:  0.83%\n",
      "  PlayingFlute:  0.83%\n",
      "  JavelinThrow:  0.83%\n",
      "  HulaHoop:  0.83%\n",
      "  HorseRiding:  0.83%\n",
      "  HorseRace:  0.83%\n",
      "  PoleVault:  0.83%\n",
      "  PullUps:  0.83%\n",
      "  Haircut:  0.83%\n",
      "  FrisbeeCatch:  0.83%\n",
      "  FloorGymnastics:  0.83%\n",
      "  PizzaTossing:  0.83%\n",
      "  Drumming:  0.83%\n",
      "  :  0.83%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6309d87b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"test\" width=\"520\" height=\"440\" controls>\n",
       "        <source src=\"\"../dataset/ucfTrainTest/test/PullUps/v_PullUps_g11_c01.avi\" type=\"video/mp4\" style=\"height:300px;width:300px\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" width=\"520\" height=\"440\" controls>\n",
    "        <source src=\"\"../dataset/ucfTrainTest/test/PullUps/v_PullUps_g11_c01.avi\" type=\"video/mp4\" style=\"height:300px;width:300px\">\n",
    "    </video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b160db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
