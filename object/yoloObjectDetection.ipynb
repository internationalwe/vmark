{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "- 1.데이터 전처리\n",
    "    - 1.1.COCO 데이터셋 전처리\n",
    "        - 1.1.1.훈련 데이터셋 전처리\n",
    "        - 1.1.2.검증 데이터셋 전처리\n",
    "    - 1.2.문 데이터셋 전처리\n",
    "    - 1.3.총 데이터셋 전처리\n",
    "    - 1.4.계단 데이터셋 전처리\n",
    "    #\n",
    "- 2.YOLO 레파지토리 다운 및 필요 패키지 설치\n",
    "- 3.모델 훈련\n",
    "- 4.테스드 데이터 만들기\n",
    "- 5.모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# coco yolo 데이터셋 각 class별 인덱스 찾는 함수\n",
    "#\n",
    "def find_index(object):\n",
    "    A = ['비행기','사과','가방','바나나','야구 방망이','야구 글로브','곰','침대','벤치','자전거','새','배','책','병','그릇','브로콜리','버스','케익','자동차','당근','고양이','핸드폰','의자','시계','소','컵','식탁','개','도넛','코끼리','소화전','포크','프리스비','기린','헤어 드라이어','핸드백','말','핫도그','키보드','연','칼','노트북','전자레인지','오토바이','마우스','오랜지','오븐','주차요금 징수기','사람','피자','화분','냉장고','리모콘','샌드위치','가위','양','싱크대','스케이트보드','스키','스노우보드','소파','숟가락','공','정지표시','여행가방','서핑보드','테디베어','테니스 라켓','넥타이','토스트기','화장실','칫솔','신호등','기차','트럭','티비','우산','꽃병','와인잔','얼룩말']\n",
    "    try :\n",
    "        idx = A.index(object)\n",
    "        return idx\n",
    "    except:\n",
    "        print(object, \"없음\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 없음\n",
      "계단 없음\n",
      "문 없음\n"
     ]
    }
   ],
   "source": [
    "nonlabel_object = []\n",
    "\n",
    "object_list = ['티비',\n",
    "    '가방',\n",
    "    '개',\n",
    "    '냉장고',\n",
    "    '병',\n",
    "    '버스',\n",
    "    '소파',\n",
    "    '핸드폰',\n",
    "    '시계',\n",
    "    '오토바이',\n",
    "    '와인잔',\n",
    "    '의자',\n",
    "    '자동차',\n",
    "    '책',\n",
    "    '칼',\n",
    "    '컵',\n",
    "    '핸드백',\n",
    "    '사람',\n",
    "    '기차',\n",
    "    '비행기',\n",
    "    '침대',\n",
    "    '자전거',\n",
    "    '우산',\n",
    "    '고양이',\n",
    "    '총',\n",
    "    '계단',\n",
    "    '문'\n",
    "    ]\n",
    "for obj in object_list:\n",
    "    idx = find_index(obj)\n",
    "    if idx == -1:\n",
    "        nonlabel_object.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['총', '계단', '문']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlabel_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 없음\n",
      "계단 없음\n",
      "문 없음\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "coco_indexTo_newIndex_dict = defaultdict(int)\n",
    "object_index_dict = defaultdict(int)\n",
    "for idx in range(len(object_list)):\n",
    "    object_index_dict[object_list[idx]] = idx\n",
    "    if find_index(object_list[idx]) != -1:\n",
    "        coco_indexTo_newIndex_dict[find_index(object_list[idx])] = idx\n",
    "\n",
    "# 지원하는 object리스트 중 coco dataset에 해당하는 인덱스 모음\n",
    "coco_index_list = list(coco_indexTo_newIndex_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'티비': 0, '가방': 1, '개': 2, '냉장고': 3, '병': 4, '버스': 5, '소파': 6, '핸드폰': 7, '시계': 8, '오토바이': 9, '와인잔': 10, '의자': 11, '자동차': 12, '책': 13, '칼': 14, '컵': 15, '핸드백': 16, '사람': 17, '기차': 18, '비행기': 19, '침대': 20, '자전거': 21, '우산': 22, '고양이': 23, '총': 24, '계단': 25, '문': 26})\n",
      "defaultdict(<class 'int'>, {75: 0, 2: 1, 27: 2, 51: 3, 13: 4, 16: 5, 60: 6, 21: 7, 23: 8, 43: 9, 78: 10, 22: 11, 18: 12, 12: 13, 40: 14, 25: 15, 35: 16, 48: 17, 73: 18, 0: 19, 7: 20, 9: 21, 76: 22, 20: 23})\n"
     ]
    }
   ],
   "source": [
    "print(object_index_dict)\n",
    "print(coco_indexTo_newIndex_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Dataset 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### COCO 훈련 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 원래 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "origianl_train_label_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/train/labels/\"\n",
    "original_train_image_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/train/images/\"\n",
    "\n",
    "# 전처리한 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "change_train_label_dir = \"../dataset/change_coco_dataset/train/labels/\"\n",
    "change_train_image_dir = \"../dataset/change_coco_dataset/train/images/\"\n",
    "\n",
    "coco_train_label_list = [name for name in os.listdir(origianl_train_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in coco_train_label_list:\n",
    "    # .txt확장자를 갖고 있는 파일 이름을 .jpg확장자를 갖고 있는 파일이름으로 변경\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #원래 라벨 및 이미지 파일 주소 변수\n",
    "    original_train_label_path = origianl_train_label_dir + label_name\n",
    "    original_train_image_path = original_train_image_dir + image_name\n",
    "\n",
    "    #전처리된 라벨 및 이미지 파일 주소 변수\n",
    "    change_train_label_path = change_train_label_dir + label_name\n",
    "    change_train_image_path = change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # 파일에 쓸 문자열 저장 변수\n",
    "        new_string = []\n",
    "        # 지원하는 object가 있는 파일 인지 확인 하는 flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # 지원하는 object class에 맞게 전처리\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # 지원하는 object가 있으면 new_string 추가\n",
    "            if int(data[0]) in coco_index_list:\n",
    "                # coco dataset의 index를 지원하는 object의 순서에 맞게 index 변경\n",
    "                data[0] = str(coco_indexTo_newIndex_dict[int(data[0])])\n",
    "                new_string.append(\" \".join(data))\n",
    "                # 지원하는 object가 라벨파일에 있으면 flag를 true로 변경\n",
    "                exist_flag = True\n",
    "        # 지원하는 object가 있으면 전처리된 라벨 데이터 파일에 쓰고 해당하는 이미지 복사\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### COCO 검증 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 원래 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "origianl_valid_label_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/valid/labels/\"\n",
    "original_valid_image_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/valid/images/\"\n",
    "\n",
    "# 전처리한 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "change_valid_label_dir = \"../dataset/change_coco_dataset/valid/labels/\"\n",
    "change_valid_image_dir = \"../dataset/change_coco_dataset/valid/images/\"\n",
    "\n",
    "coco_valid_label_list = [path for path in os.listdir(origianl_valid_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in coco_valid_label_list:\n",
    "    # .txt확장자를 갖고 있는 파일 이름을 .jpg확장자를 갖고 있는 파일이름으로 변경\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #원래 라벨 및 이미지 파일 주소 변수\n",
    "    original_valid_label_path = origianl_valid_label_dir + label_name\n",
    "    original_valid_image_path = original_valid_image_dir + image_name\n",
    "\n",
    "    #전처리된 라벨 및 이미지 파일 주소 변수\n",
    "    change_valid_label_path = change_valid_label_dir + label_name\n",
    "    change_valid_image_path = change_valid_image_dir + image_name\n",
    "\n",
    "    with open(original_valid_label_path,'r') as file:\n",
    "        # 파일에 쓸 문자열 저장 변수\n",
    "        new_string = []\n",
    "        # 지원하는 object가 있는 파일 인지 확인 하는 flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # 지원하는 object class에 맞게 전처리\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # 지원하는 object가 있으면 new_string 추가\n",
    "            if int(data[0]) in coco_index_list:\n",
    "                # coco dataset의 index를 지원하는 object의 순서에 맞게 index 변경\n",
    "                data[0] = str(coco_indexTo_newIndex_dict[int(data[0])])\n",
    "                new_string.append(\" \".join(data))\n",
    "                # 지원하는 object가 라벨파일에 있으면 flag를 true로 변경\n",
    "                exist_flag = True\n",
    "        # 지원하는 object가 있으면 전처리된 라벨 데이터 파일에 쓰고 해당하는 이미지 복사\n",
    "        if exist_flag == True:\n",
    "            with open(change_valid_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_valid_image_path, change_valid_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 문 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 일부분 오류 데이터 삭제했음\n",
    "\n",
    "import os\n",
    "# 원래 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "door1_origianl_train_label_dir = \"../dataset/DoorDetect-Dataset-master/labels/\"\n",
    "door1_original_train_image_dir = \"../dataset/DoorDetect-Dataset-master/images/\"\n",
    "\n",
    "# 전처리한 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "door1_change_train_label_dir = \"../dataset/change_door_dataset/train/labels/\"\n",
    "door1_change_train_image_dir = \"../dataset/change_door_dataset/train/images/\"\n",
    "\n",
    "door1_train_label_list = [name for name in os.listdir(door1_origianl_train_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in door1_train_label_list:\n",
    "    if len(label_name) >=110:\n",
    "        continue\n",
    "\n",
    "    # .txt확장자를 갖고 있는 파일 이름을 .jpg확장자를 갖고 있는 파일이름으로 변경\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #원래 라벨 및 이미지 파일 주소 변수\n",
    "    original_train_label_path = door1_origianl_train_label_dir + label_name\n",
    "    original_train_image_path = door1_original_train_image_dir + image_name\n",
    "\n",
    "    #전처리된 라벨 및 이미지 파일 주소 변수\n",
    "    change_train_label_path = door1_change_train_label_dir + label_name\n",
    "    change_train_image_path = door1_change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # 파일에 쓸 문자열 저장 변수\n",
    "        new_string = []\n",
    "        # 지원하는 object가 있는 파일 인지 확인 하는 flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # 지원하는 object class에 맞게 전처리\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # 문에 해당하는 id로 class 인덱스\n",
    "            if data[0] == \"0\" or data[0] == \"2\" or data[0] == \"3\":\n",
    "                data[0] = str(26)\n",
    "                new_string.append(\" \".join(data))\n",
    "                # 지원하는 object가 라벨파일에 있으면 flag를 true로 변경\n",
    "                exist_flag = True\n",
    "        # 지원하는 object가 있으면 전처리된 라벨 데이터 파일에 쓰고 해당하는 이미지 복사\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "# 이미지,라벨 데이터 이름 정렬\n",
    "image_list = sorted([_ for _ in os.listdir(door1_change_train_image_dir)])\n",
    "label_list = sorted([_ for _ in os.listdir(door1_change_train_label_dir)])\n",
    "# train, test로 나누기\n",
    "train_names, valid_names = train_test_split(image_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "trainLabels_names, validLabels_names = train_test_split(label_list, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train 이미지랑 라벨 같은지 확인\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train 이미지랑 라벨 같은지 확인\n",
    "for image, label in zip(valid_names,validLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  shutil.move(door1_change_train_image_dir+image,\"../dataset/change_door_dataset/valid/images/\")\n",
    "  shutil.move(door1_change_train_label_dir+label,\"../dataset/change_door_dataset/valid/labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 총 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 원래 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "gun1_origianl_train_label_dir = \"../dataset/Pistols.v1-resize-416x416.yolov5pytorch/export/labels/\"\n",
    "gun1_original_train_image_dir = \"../dataset/Pistols.v1-resize-416x416.yolov5pytorch/export/images/\"\n",
    "\n",
    "# 전처리한 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "gun1_change_train_label_dir = \"../dataset/change_gun_dataset/train/labels/\"\n",
    "gun1_change_train_image_dir = \"../dataset/change_gun_dataset/train/images/\"\n",
    "\n",
    "gun1_train_label_list = [name for name in os.listdir(gun1_origianl_train_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in gun1_train_label_list:\n",
    "\n",
    "    # .txt확장자를 갖고 있는 파일 이름을 .jpg확장자를 갖고 있는 파일이름으로 변경\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #원래 라벨 및 이미지 파일 주소 변수\n",
    "    original_train_label_path = gun1_origianl_train_label_dir + label_name\n",
    "    original_train_image_path = gun1_original_train_image_dir + image_name\n",
    "\n",
    "    #전처리된 라벨 및 이미지 파일 주소 변수\n",
    "    change_train_label_path = gun1_change_train_label_dir + label_name\n",
    "    change_train_image_path = gun1_change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # 파일에 쓸 문자열 저장 변수\n",
    "        new_string = []\n",
    "        # 지원하는 object가 있는 파일 인지 확인 하는 flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # 지원하는 object class에 맞게 전처리\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # 문에 해당하는 id로 class 인덱스\n",
    "            if data[0] == \"0\":\n",
    "                data[0] = str(24)\n",
    "                new_string.append(\" \".join(data))\n",
    "                # 지원하는 object가 라벨파일에 있으면 flag를 true로 변경\n",
    "                exist_flag = True\n",
    "        # 지원하는 object가 있으면 전처리된 라벨 데이터 파일에 쓰고 해당하는 이미지 복사\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# 이미지,라벨 데이터 이름 정렬\n",
    "image_list = sorted([_ for _ in os.listdir(gun1_change_train_image_dir)])\n",
    "label_list = sorted([_ for _ in os.listdir(gun1_change_train_label_dir)])\n",
    "# train, test로 나누기\n",
    "train_names, valid_names = train_test_split(image_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "trainLabels_names, validLabels_names = train_test_split(label_list, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train 이미지랑 라벨 같은지 확인\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train 이미지랑 라벨 같은지 확인\n",
    "for image, label in zip(valid_names,validLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  shutil.move(gun1_change_train_image_dir+image,\"../dataset/change_gun_dataset/valid/images/\")\n",
    "  shutil.move(gun1_change_train_label_dir+label,\"../dataset/change_gun_dataset/valid/labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 계단 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 원래 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "stair1_origianl_train_label_dir = \"../dataset/stairs_dataset/train/\"\n",
    "stair1_original_train_image_dir = \"../dataset/stairs_dataset/train/\"\n",
    "\n",
    "# 전처리한 coco 데이터셋 라벨, 이미지 디렉토리 주소\n",
    "stair1_change_train_label_dir = \"../dataset/change_stair1_dataset/train/labels/\"\n",
    "stair1_change_train_image_dir = \"../dataset/change_stair1_dataset/train/images/\"\n",
    "\n",
    "stair1_train_label_list = [name for name in os.listdir(stair1_origianl_train_label_dir) if name.split(\".\")[-1] == \"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in stair1_train_label_list:\n",
    "\n",
    "    # .txt확장자를 갖고 있는 파일 이름을 .jpg확장자를 갖고 있는 파일이름으로 변경\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #원래 라벨 및 이미지 파일 주소 변수\n",
    "    original_train_label_path = stair1_origianl_train_label_dir + label_name\n",
    "    original_train_image_path = stair1_original_train_image_dir + image_name\n",
    "\n",
    "    #전처리된 라벨 및 이미지 파일 주소 변수\n",
    "    change_train_label_path = stair1_change_train_label_dir + label_name\n",
    "    change_train_image_path = stair1_change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # 파일에 쓸 문자열 저장 변수\n",
    "        new_string = []\n",
    "        # 지원하는 object가 있는 파일 인지 확인 하는 flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # 지원하는 object class에 맞게 전처리\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # 문에 해당하는 id로 class 인덱스\n",
    "            if data[0] == \"0\":\n",
    "                data[0] = str(25)\n",
    "                new_string.append(\" \".join(data))\n",
    "                # 지원하는 object가 라벨파일에 있으면 flag를 true로 변경\n",
    "                exist_flag = True\n",
    "        # 지원하는 object가 있으면 전처리된 라벨 데이터 파일에 쓰고 해당하는 이미지 복사\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# 이미지,라벨 데이터 이름 정렬\n",
    "image_list = sorted([_ for _ in os.listdir(stair1_change_train_image_dir)])\n",
    "label_list = sorted([_ for _ in os.listdir(stair1_change_train_label_dir)])\n",
    "# train, test로 나누기\n",
    "train_names, valid_names = train_test_split(image_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "trainLabels_names, validLabels_names = train_test_split(label_list, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train 이미지랑 라벨 같은지 확인\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train 이미지랑 라벨 같은지 확인\n",
    "for image, label in zip(valid_names,validLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  shutil.move(stair1_change_train_image_dir+image,\"../dataset/change_stair1_dataset/valid/images/\")\n",
    "  shutil.move(stair1_change_train_label_dir+label,\"../dataset/change_stair1_dataset/valid/labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO 레파지토리 다운 및 필요 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Yolov5 github 레포지토리 clone\n",
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/src/datasets/code/yolov5-master\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 필요한 모듈 설치\n",
    "!pip install -U -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=./data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 2022-6-24 Python-3.8.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 8192MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=27\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     86304  models.yolo.Detect                      [27, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7092448 parameters, 7092448 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/train/images/000000201706_jpg.rf.7c891d8778f166e1bf2b1fe1b3571d3c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/train/images/000000295376_jpg.rf.ca541ab3589f558ad46ef19d4c8b7995.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/va\u001b[0m\n",
      "Plotting labels to runs/train/exp13/labels.jpg... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.07 anchors/target, 0.953 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found: 25495 of 521754 labels are < 3 pixels in size\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 511487 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6972: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9769 best possible recall, 4.41 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=320, metric_all=0.295/0.685-mean/best, past_thr=0.474-mean: 5,8, 9,13, 11,30, 24,18, 26,41, 61,46, 37,90, 85,121, 163,176\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp13\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     0/299    0.946G   0.07737   0.03698    0.0384        27       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30806      0.544      0.328      0.314      0.184\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     1/299     1.57G   0.07075   0.03729    0.0256         8       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.532      0.336      0.327      0.194\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     2/299     1.57G   0.07195   0.03867   0.02696        19       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.504      0.339      0.316      0.183\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     3/299     1.58G   0.07177   0.03902   0.02706        18       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.496      0.348      0.326      0.193\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     4/299     1.58G   0.07057   0.03873   0.02576        27       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.513      0.364      0.341      0.202\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     5/299     1.58G   0.06982   0.03867   0.02511         6       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.518      0.371      0.354      0.211\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     6/299     1.58G   0.06952   0.03865   0.02462         9       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.519      0.376      0.362      0.216\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     7/299     1.58G    0.0692   0.03855   0.02446        16       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.519      0.383      0.365      0.219\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     8/299     1.58G   0.06904   0.03841   0.02418         3       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.522      0.386      0.369      0.221\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     9/299     1.58G   0.06897   0.03836   0.02413        16       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.517      0.396      0.374      0.224\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    10/299     1.58G   0.06882   0.03837   0.02393        19       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.521      0.394      0.377      0.225\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    11/299     1.58G   0.06871   0.03829   0.02386        29       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.522      0.395      0.379      0.227\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    12/299     1.58G    0.0686   0.03852   0.02371        14       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.505      0.398       0.38      0.228\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    13/299     1.58G   0.06863   0.03833   0.02368         9       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.509        0.4      0.381      0.229\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    14/299     1.58G   0.06839   0.03812   0.02368        35       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.514      0.399      0.382       0.23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    15/299     1.58G   0.06833    0.0381   0.02363        32       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.531      0.393      0.383       0.23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    16/299     1.58G   0.06846   0.03823   0.02352        29       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.531      0.394      0.383       0.23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    17/299     1.58G   0.06828    0.0383   0.02345        17       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.528      0.397      0.384      0.231\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    18/299     1.58G   0.06827   0.03833   0.02334        13       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.531      0.395      0.385      0.232\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    19/299     1.58G   0.06825   0.03823   0.02341        25       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.529      0.396      0.385      0.232\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    20/299     1.58G   0.06829   0.03829   0.02337        40       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.526      0.398      0.386      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    21/299     1.58G   0.06813   0.03818   0.02337        28       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.525        0.4      0.386      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    22/299     1.58G   0.06811   0.03814   0.02328        11       320: 100%|███\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.512      0.404      0.386      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    23/299     1.58G    0.0681   0.03827    0.0232        34       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.514      0.406      0.387      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    24/299     1.58G   0.06796    0.0381   0.02322        17       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.521      0.404      0.388      0.235\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    25/299     1.58G   0.06796    0.0379   0.02304        15       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.524      0.405      0.389      0.235\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    26/299     1.58G   0.06794   0.03813   0.02302        23       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.526      0.406       0.39      0.236\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    27/299     1.58G   0.06789   0.03815   0.02311         4       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.522      0.407       0.39      0.236\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    28/299     1.58G   0.06802   0.03831   0.02312        16       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.524      0.405      0.391      0.237\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    29/299     1.58G   0.06782   0.03824   0.02301        33       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819       0.52      0.411      0.392      0.238\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    30/299     1.58G   0.06793   0.03821   0.02295         8       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.532      0.405      0.391      0.238\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    31/299     1.58G   0.06784    0.0381   0.02301        15       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.535      0.406      0.392      0.238\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    32/299     1.58G   0.06777     0.038   0.02282         6       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.534      0.407      0.393      0.239\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    33/299     1.58G   0.06791   0.03822   0.02286        29       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.534      0.407      0.393      0.239\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    34/299     1.58G   0.06777   0.03823   0.02304       153       320:  44%|███^C\n",
      "    34/299     1.58G   0.06777   0.03823   0.02304       153       320:  44%|███\n",
      "Traceback (most recent call last):\n",
      "  File \"./train.py\", line 670, in <module>\n",
      "    main(opt)\n",
      "  File \"./train.py\", line 565, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"./train.py\", line 360, in train\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 363, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "### 훈련시키기\n",
    "!python ./train.py --data \"./data.yaml\" --img 320 --epochs 300 --batch 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.9.0 at http://e2c1159c89b8:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir runs/train/exp13/result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "filepath = '../dataset/movie/PARASITE.2019.1080p.FHDRip.H264.AAC-NonDRM.mp4'\n",
    "video = cv2.VideoCapture(filepath) #'' 사이에 사용할 비디오 파일의 경로 및 이름을 넣어주도록 함\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Could not Open :\", filepath)\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 189956\n",
      "width : 1920\n",
      "height : 1080\n",
      "fps : 23.976150195517942\n"
     ]
    }
   ],
   "source": [
    "#불러온 비디오 파일의 정보 출력\n",
    "length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(\"length :\", length)\n",
    "print(\"width :\", width)\n",
    "print(\"height :\", height)\n",
    "print(\"fps :\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frame number : 10\n",
      "Saved frame number : 20\n",
      "Saved frame number : 30\n",
      "Saved frame number : 40\n",
      "Saved frame number : 50\n",
      "Saved frame number : 60\n",
      "Saved frame number : 70\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "filepath = \"../dataset/parasite\"\n",
    "while(video.isOpened()):\n",
    "    ret, image = video.read()\n",
    "    if(int(video.get(1)) % 10 == 0): #앞서 불러온 fps 값을 사용하여 1초마다 추출\n",
    "        cv2.imwrite(filepath + \"/frame%d.jpg\" % count, image)\n",
    "        print('Saved frame number :', str(int(video.get(1))))\n",
    "        count += 1\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./yolov5-master/runs/train/exp13/weights/best.pt'], source=../dataset/parasite, data=yolov5-master/data/coco128.yaml, imgsz=[320, 320], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5-master/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 🚀 2022-6-24 Python-3.8.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7082944 parameters, 0 gradients, 16.0 GFLOPs\n",
      "image 287/18995 /usr/src/datasets/dataset/parasite/frame10254.jpg: 192x320 2 사람s, Done. (0.011s)\n",
      "image 288/18995 /usr/src/datasets/dataset/parasite/frame10255.jpg: 192x320 1 핸드폰, 1 사람, Done. (0.008s)\n",
      "image 289/18995 /usr/src/datasets/dataset/parasite/frame10256.jpg: 192x320 1 핸드폰, 2 사람s, Done. (0.013s)\n",
      "image 290/18995 /usr/src/datasets/dataset/parasite/frame10257.jpg: 192x320 1 핸드폰, 2 사람s, Done. (0.020s)\n",
      "image 291/18995 /usr/src/datasets/dataset/parasite/frame10258.jpg: 192x320 1 핸드폰, 2 사람s, Done. (0.010s)\n",
      "image 292/18995 /usr/src/datasets/dataset/parasite/frame10259.jpg: 192x320 1 핸드폰, 2 사람s, Done. (0.010s)\n",
      "image 293/18995 /usr/src/datasets/dataset/parasite/frame1026.jpg: 192x320 2 사람s, Done. (0.010s)\n",
      "image 294/18995 /usr/src/datasets/dataset/parasite/frame10260.jpg: 192x320 1 핸드폰, 1 사람, Done. (0.009s)\n",
      "image 295/18995 /usr/src/datasets/dataset/parasite/frame10261.jpg: 192x320 1 사람, Done. (0.009s)\n",
      "image 296/18995 /usr/src/datasets/dataset/parasite/frame10262.jpg: 192x320 1 사람, Done. (0.008s)\n",
      "image 297/18995 /usr/src/datasets/dataset/parasite/frame10263.jpg: 192x320 1 핸드폰, 1 사람, Done. (0.008s)\n",
      "image 298/18995 /usr/src/datasets/dataset/parasite/frame10264.jpg: 192x320 1 핸드폰, Done. (0.010s)\n",
      "image 299/18995 /usr/src/datasets/dataset/parasite/frame10265.jpg: 192x320 1 핸드폰, 1 사람, Done. (0.009s)\n",
      "image 300/18995 /usr/src/datasets/dataset/parasite/frame10266.jpg: 192x320 1 핸드폰, 1 사람, Done. (0.009s)\n",
      "image 301/18995 /usr/src/datasets/dataset/parasite/frame10267.jpg: 192x320 1 핸드폰, 1 사람, Done. (0.009s)\n",
      "image 302/18995 /usr/src/datasets/dataset/parasite/frame10268.jpg: 192x320 1 핸드폰, 1 사람, Done. (0.009s)\n",
      "image 303/18995 /usr/src/datasets/dataset/parasite/frame10269.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.010s)\n",
      "image 304/18995 /usr/src/datasets/dataset/parasite/frame1027.jpg: 192x320 4 사람s, Done. (0.009s)\n",
      "image 305/18995 /usr/src/datasets/dataset/parasite/frame10270.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.009s)\n",
      "image 306/18995 /usr/src/datasets/dataset/parasite/frame10271.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.018s)\n",
      "image 307/18995 /usr/src/datasets/dataset/parasite/frame10272.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.010s)\n",
      "image 308/18995 /usr/src/datasets/dataset/parasite/frame10273.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.010s)\n",
      "image 309/18995 /usr/src/datasets/dataset/parasite/frame10274.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.017s)\n",
      "image 310/18995 /usr/src/datasets/dataset/parasite/frame10275.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.010s)\n",
      "image 311/18995 /usr/src/datasets/dataset/parasite/frame10276.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.012s)\n",
      "image 312/18995 /usr/src/datasets/dataset/parasite/frame10277.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.012s)\n",
      "image 313/18995 /usr/src/datasets/dataset/parasite/frame10278.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.013s)\n",
      "image 314/18995 /usr/src/datasets/dataset/parasite/frame10279.jpg: 192x320 1 핸드폰, 3 사람s, Done. (0.014s)\n",
      "image 315/18995 /usr/src/datasets/dataset/parasite/frame1028.jpg: 192x320 5 사람s, Done. (0.013s)\n"
     ]
    }
   ],
   "source": [
    "videoPath = '../dataset/movie/PARASITE.2019.1080p.FHDRip.H264.AAC-NonDRM.mp4'\n",
    "!python ./yolov5-master/detect.py --weights ./yolov5-master/runs/train/exp13/weights/best.pt --source ../dataset/movie/PARASITE.2019.1080p.FHDRip.H264.AAC-NonDRM.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#코코의외의 데이터셋\n",
    "1. 총\n",
    "- roboflow pistols dataset : https://public.roboflow.com/object-detection/pistols/1 (Pistols.v1-resize-416x416.yolov5pytorch.zip)\n",
    "2. 계단\n",
    "- Staircase Dataset : https://data.mendeley.com/datasets/7m97gp4yz9/1 (7m97gp4yz9-1.zip)\n",
    "3. 문\n",
    "- DoorDetect-Dataset : https://github.com/MiguelARD/DoorDetect-Dataset (DoorDetect-Dataset-master.zip) 1213"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
