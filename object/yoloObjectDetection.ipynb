{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª©ì°¨\n",
    "- 1.ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    - 1.1.COCO ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
    "        - 1.1.1.í›ˆë ¨ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
    "        - 1.1.2.ê²€ì¦ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
    "    - 1.2.ë¬¸ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
    "    - 1.3.ì´ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
    "    - 1.4.ê³„ë‹¨ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
    "    #\n",
    "- 2.YOLO ë ˆíŒŒì§€í† ë¦¬ ë‹¤ìš´ ë° í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "- 3.ëª¨ë¸ í›ˆë ¨\n",
    "- 4.í…ŒìŠ¤ë“œ ë°ì´í„° ë§Œë“¤ê¸°\n",
    "- 5.ëª¨ë¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# coco yolo ë°ì´í„°ì…‹ ê° classë³„ ì¸ë±ìŠ¤ ì°¾ëŠ” í•¨ìˆ˜\n",
    "#\n",
    "def find_index(object):\n",
    "    A = ['ë¹„í–‰ê¸°','ì‚¬ê³¼','ê°€ë°©','ë°”ë‚˜ë‚˜','ì•¼êµ¬ ë°©ë§ì´','ì•¼êµ¬ ê¸€ë¡œë¸Œ','ê³°','ì¹¨ëŒ€','ë²¤ì¹˜','ìì „ê±°','ìƒˆ','ë°°','ì±…','ë³‘','ê·¸ë¦‡','ë¸Œë¡œì½œë¦¬','ë²„ìŠ¤','ì¼€ìµ','ìë™ì°¨','ë‹¹ê·¼','ê³ ì–‘ì´','í•¸ë“œí°','ì˜ì','ì‹œê³„','ì†Œ','ì»µ','ì‹íƒ','ê°œ','ë„ë„›','ì½”ë¼ë¦¬','ì†Œí™”ì „','í¬í¬','í”„ë¦¬ìŠ¤ë¹„','ê¸°ë¦°','í—¤ì–´ ë“œë¼ì´ì–´','í•¸ë“œë°±','ë§','í•«ë„ê·¸','í‚¤ë³´ë“œ','ì—°','ì¹¼','ë…¸íŠ¸ë¶','ì „ìë ˆì¸ì§€','ì˜¤í† ë°”ì´','ë§ˆìš°ìŠ¤','ì˜¤ëœì§€','ì˜¤ë¸','ì£¼ì°¨ìš”ê¸ˆ ì§•ìˆ˜ê¸°','ì‚¬ëŒ','í”¼ì','í™”ë¶„','ëƒ‰ì¥ê³ ','ë¦¬ëª¨ì½˜','ìƒŒë“œìœ„ì¹˜','ê°€ìœ„','ì–‘','ì‹±í¬ëŒ€','ìŠ¤ì¼€ì´íŠ¸ë³´ë“œ','ìŠ¤í‚¤','ìŠ¤ë…¸ìš°ë³´ë“œ','ì†ŒíŒŒ','ìˆŸê°€ë½','ê³µ','ì •ì§€í‘œì‹œ','ì—¬í–‰ê°€ë°©','ì„œí•‘ë³´ë“œ','í…Œë””ë² ì–´','í…Œë‹ˆìŠ¤ ë¼ì¼“','ë„¥íƒ€ì´','í† ìŠ¤íŠ¸ê¸°','í™”ì¥ì‹¤','ì¹«ì†”','ì‹ í˜¸ë“±','ê¸°ì°¨','íŠ¸ëŸ­','í‹°ë¹„','ìš°ì‚°','ê½ƒë³‘','ì™€ì¸ì”','ì–¼ë£©ë§']\n",
    "    try :\n",
    "        idx = A.index(object)\n",
    "        return idx\n",
    "    except:\n",
    "        print(object, \"ì—†ìŒ\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì—†ìŒ\n",
      "ê³„ë‹¨ ì—†ìŒ\n",
      "ë¬¸ ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "nonlabel_object = []\n",
    "\n",
    "object_list = ['í‹°ë¹„',\n",
    "    'ê°€ë°©',\n",
    "    'ê°œ',\n",
    "    'ëƒ‰ì¥ê³ ',\n",
    "    'ë³‘',\n",
    "    'ë²„ìŠ¤',\n",
    "    'ì†ŒíŒŒ',\n",
    "    'í•¸ë“œí°',\n",
    "    'ì‹œê³„',\n",
    "    'ì˜¤í† ë°”ì´',\n",
    "    'ì™€ì¸ì”',\n",
    "    'ì˜ì',\n",
    "    'ìë™ì°¨',\n",
    "    'ì±…',\n",
    "    'ì¹¼',\n",
    "    'ì»µ',\n",
    "    'í•¸ë“œë°±',\n",
    "    'ì‚¬ëŒ',\n",
    "    'ê¸°ì°¨',\n",
    "    'ë¹„í–‰ê¸°',\n",
    "    'ì¹¨ëŒ€',\n",
    "    'ìì „ê±°',\n",
    "    'ìš°ì‚°',\n",
    "    'ê³ ì–‘ì´',\n",
    "    'ì´',\n",
    "    'ê³„ë‹¨',\n",
    "    'ë¬¸'\n",
    "    ]\n",
    "for obj in object_list:\n",
    "    idx = find_index(obj)\n",
    "    if idx == -1:\n",
    "        nonlabel_object.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì´', 'ê³„ë‹¨', 'ë¬¸']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlabel_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì—†ìŒ\n",
      "ê³„ë‹¨ ì—†ìŒ\n",
      "ë¬¸ ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "coco_indexTo_newIndex_dict = defaultdict(int)\n",
    "object_index_dict = defaultdict(int)\n",
    "for idx in range(len(object_list)):\n",
    "    object_index_dict[object_list[idx]] = idx\n",
    "    if find_index(object_list[idx]) != -1:\n",
    "        coco_indexTo_newIndex_dict[find_index(object_list[idx])] = idx\n",
    "\n",
    "# ì§€ì›í•˜ëŠ” objectë¦¬ìŠ¤íŠ¸ ì¤‘ coco datasetì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ ëª¨ìŒ\n",
    "coco_index_list = list(coco_indexTo_newIndex_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'í‹°ë¹„': 0, 'ê°€ë°©': 1, 'ê°œ': 2, 'ëƒ‰ì¥ê³ ': 3, 'ë³‘': 4, 'ë²„ìŠ¤': 5, 'ì†ŒíŒŒ': 6, 'í•¸ë“œí°': 7, 'ì‹œê³„': 8, 'ì˜¤í† ë°”ì´': 9, 'ì™€ì¸ì”': 10, 'ì˜ì': 11, 'ìë™ì°¨': 12, 'ì±…': 13, 'ì¹¼': 14, 'ì»µ': 15, 'í•¸ë“œë°±': 16, 'ì‚¬ëŒ': 17, 'ê¸°ì°¨': 18, 'ë¹„í–‰ê¸°': 19, 'ì¹¨ëŒ€': 20, 'ìì „ê±°': 21, 'ìš°ì‚°': 22, 'ê³ ì–‘ì´': 23, 'ì´': 24, 'ê³„ë‹¨': 25, 'ë¬¸': 26})\n",
      "defaultdict(<class 'int'>, {75: 0, 2: 1, 27: 2, 51: 3, 13: 4, 16: 5, 60: 6, 21: 7, 23: 8, 43: 9, 78: 10, 22: 11, 18: 12, 12: 13, 40: 14, 25: 15, 35: 16, 48: 17, 73: 18, 0: 19, 7: 20, 9: 21, 76: 22, 20: 23})\n"
     ]
    }
   ],
   "source": [
    "print(object_index_dict)\n",
    "print(coco_indexTo_newIndex_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Dataset ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO ë°ì´í„°ì…‹ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### COCO í›ˆë ¨ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ì›ë˜ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "origianl_train_label_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/train/labels/\"\n",
    "original_train_image_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/train/images/\"\n",
    "\n",
    "# ì „ì²˜ë¦¬í•œ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "change_train_label_dir = \"../dataset/change_coco_dataset/train/labels/\"\n",
    "change_train_image_dir = \"../dataset/change_coco_dataset/train/images/\"\n",
    "\n",
    "coco_train_label_list = [name for name in os.listdir(origianl_train_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in coco_train_label_list:\n",
    "    # .txtí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ ì´ë¦„ì„ .jpgí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ì´ë¦„ìœ¼ë¡œ ë³€ê²½\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #ì›ë˜ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    original_train_label_path = origianl_train_label_dir + label_name\n",
    "    original_train_image_path = original_train_image_dir + image_name\n",
    "\n",
    "    #ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    change_train_label_path = change_train_label_dir + label_name\n",
    "    change_train_image_path = change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # íŒŒì¼ì— ì“¸ ë¬¸ìì—´ ì €ì¥ ë³€ìˆ˜\n",
    "        new_string = []\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆëŠ” íŒŒì¼ ì¸ì§€ í™•ì¸ í•˜ëŠ” flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # ì§€ì›í•˜ëŠ” object classì— ë§ê²Œ ì „ì²˜ë¦¬\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # ì§€ì›í•˜ëŠ” objectê°€ ìˆìœ¼ë©´ new_string ì¶”ê°€\n",
    "            if int(data[0]) in coco_index_list:\n",
    "                # coco datasetì˜ indexë¥¼ ì§€ì›í•˜ëŠ” objectì˜ ìˆœì„œì— ë§ê²Œ index ë³€ê²½\n",
    "                data[0] = str(coco_indexTo_newIndex_dict[int(data[0])])\n",
    "                new_string.append(\" \".join(data))\n",
    "                # ì§€ì›í•˜ëŠ” objectê°€ ë¼ë²¨íŒŒì¼ì— ìˆìœ¼ë©´ flagë¥¼ trueë¡œ ë³€ê²½\n",
    "                exist_flag = True\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆìœ¼ë©´ ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë°ì´í„° íŒŒì¼ì— ì“°ê³  í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ë³µì‚¬\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### COCO ê²€ì¦ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ì›ë˜ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "origianl_valid_label_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/valid/labels/\"\n",
    "original_valid_image_dir = \"../dataset/Microsoft COCO.v2-raw.yolov5pytorch/valid/images/\"\n",
    "\n",
    "# ì „ì²˜ë¦¬í•œ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "change_valid_label_dir = \"../dataset/change_coco_dataset/valid/labels/\"\n",
    "change_valid_image_dir = \"../dataset/change_coco_dataset/valid/images/\"\n",
    "\n",
    "coco_valid_label_list = [path for path in os.listdir(origianl_valid_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in coco_valid_label_list:\n",
    "    # .txtí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ ì´ë¦„ì„ .jpgí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ì´ë¦„ìœ¼ë¡œ ë³€ê²½\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #ì›ë˜ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    original_valid_label_path = origianl_valid_label_dir + label_name\n",
    "    original_valid_image_path = original_valid_image_dir + image_name\n",
    "\n",
    "    #ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    change_valid_label_path = change_valid_label_dir + label_name\n",
    "    change_valid_image_path = change_valid_image_dir + image_name\n",
    "\n",
    "    with open(original_valid_label_path,'r') as file:\n",
    "        # íŒŒì¼ì— ì“¸ ë¬¸ìì—´ ì €ì¥ ë³€ìˆ˜\n",
    "        new_string = []\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆëŠ” íŒŒì¼ ì¸ì§€ í™•ì¸ í•˜ëŠ” flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # ì§€ì›í•˜ëŠ” object classì— ë§ê²Œ ì „ì²˜ë¦¬\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # ì§€ì›í•˜ëŠ” objectê°€ ìˆìœ¼ë©´ new_string ì¶”ê°€\n",
    "            if int(data[0]) in coco_index_list:\n",
    "                # coco datasetì˜ indexë¥¼ ì§€ì›í•˜ëŠ” objectì˜ ìˆœì„œì— ë§ê²Œ index ë³€ê²½\n",
    "                data[0] = str(coco_indexTo_newIndex_dict[int(data[0])])\n",
    "                new_string.append(\" \".join(data))\n",
    "                # ì§€ì›í•˜ëŠ” objectê°€ ë¼ë²¨íŒŒì¼ì— ìˆìœ¼ë©´ flagë¥¼ trueë¡œ ë³€ê²½\n",
    "                exist_flag = True\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆìœ¼ë©´ ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë°ì´í„° íŒŒì¼ì— ì“°ê³  í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ë³µì‚¬\n",
    "        if exist_flag == True:\n",
    "            with open(change_valid_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_valid_image_path, change_valid_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ë¬¸ ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ì¼ë¶€ë¶„ ì˜¤ë¥˜ ë°ì´í„° ì‚­ì œí–ˆìŒ\n",
    "\n",
    "import os\n",
    "# ì›ë˜ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "door1_origianl_train_label_dir = \"../dataset/DoorDetect-Dataset-master/labels/\"\n",
    "door1_original_train_image_dir = \"../dataset/DoorDetect-Dataset-master/images/\"\n",
    "\n",
    "# ì „ì²˜ë¦¬í•œ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "door1_change_train_label_dir = \"../dataset/change_door_dataset/train/labels/\"\n",
    "door1_change_train_image_dir = \"../dataset/change_door_dataset/train/images/\"\n",
    "\n",
    "door1_train_label_list = [name for name in os.listdir(door1_origianl_train_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in door1_train_label_list:\n",
    "    if len(label_name) >=110:\n",
    "        continue\n",
    "\n",
    "    # .txtí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ ì´ë¦„ì„ .jpgí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ì´ë¦„ìœ¼ë¡œ ë³€ê²½\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #ì›ë˜ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    original_train_label_path = door1_origianl_train_label_dir + label_name\n",
    "    original_train_image_path = door1_original_train_image_dir + image_name\n",
    "\n",
    "    #ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    change_train_label_path = door1_change_train_label_dir + label_name\n",
    "    change_train_image_path = door1_change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # íŒŒì¼ì— ì“¸ ë¬¸ìì—´ ì €ì¥ ë³€ìˆ˜\n",
    "        new_string = []\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆëŠ” íŒŒì¼ ì¸ì§€ í™•ì¸ í•˜ëŠ” flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # ì§€ì›í•˜ëŠ” object classì— ë§ê²Œ ì „ì²˜ë¦¬\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # ë¬¸ì— í•´ë‹¹í•˜ëŠ” idë¡œ class ì¸ë±ìŠ¤\n",
    "            if data[0] == \"0\" or data[0] == \"2\" or data[0] == \"3\":\n",
    "                data[0] = str(26)\n",
    "                new_string.append(\" \".join(data))\n",
    "                # ì§€ì›í•˜ëŠ” objectê°€ ë¼ë²¨íŒŒì¼ì— ìˆìœ¼ë©´ flagë¥¼ trueë¡œ ë³€ê²½\n",
    "                exist_flag = True\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆìœ¼ë©´ ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë°ì´í„° íŒŒì¼ì— ì“°ê³  í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ë³µì‚¬\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "# ì´ë¯¸ì§€,ë¼ë²¨ ë°ì´í„° ì´ë¦„ ì •ë ¬\n",
    "image_list = sorted([_ for _ in os.listdir(door1_change_train_image_dir)])\n",
    "label_list = sorted([_ for _ in os.listdir(door1_change_train_label_dir)])\n",
    "# train, testë¡œ ë‚˜ëˆ„ê¸°\n",
    "train_names, valid_names = train_test_split(image_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "trainLabels_names, validLabels_names = train_test_split(label_list, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train ì´ë¯¸ì§€ë‘ ë¼ë²¨ ê°™ì€ì§€ í™•ì¸\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train ì´ë¯¸ì§€ë‘ ë¼ë²¨ ê°™ì€ì§€ í™•ì¸\n",
    "for image, label in zip(valid_names,validLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  shutil.move(door1_change_train_image_dir+image,\"../dataset/change_door_dataset/valid/images/\")\n",
    "  shutil.move(door1_change_train_label_dir+label,\"../dataset/change_door_dataset/valid/labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ì´ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ì›ë˜ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "gun1_origianl_train_label_dir = \"../dataset/Pistols.v1-resize-416x416.yolov5pytorch/export/labels/\"\n",
    "gun1_original_train_image_dir = \"../dataset/Pistols.v1-resize-416x416.yolov5pytorch/export/images/\"\n",
    "\n",
    "# ì „ì²˜ë¦¬í•œ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "gun1_change_train_label_dir = \"../dataset/change_gun_dataset/train/labels/\"\n",
    "gun1_change_train_image_dir = \"../dataset/change_gun_dataset/train/images/\"\n",
    "\n",
    "gun1_train_label_list = [name for name in os.listdir(gun1_origianl_train_label_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in gun1_train_label_list:\n",
    "\n",
    "    # .txtí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ ì´ë¦„ì„ .jpgí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ì´ë¦„ìœ¼ë¡œ ë³€ê²½\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #ì›ë˜ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    original_train_label_path = gun1_origianl_train_label_dir + label_name\n",
    "    original_train_image_path = gun1_original_train_image_dir + image_name\n",
    "\n",
    "    #ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    change_train_label_path = gun1_change_train_label_dir + label_name\n",
    "    change_train_image_path = gun1_change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # íŒŒì¼ì— ì“¸ ë¬¸ìì—´ ì €ì¥ ë³€ìˆ˜\n",
    "        new_string = []\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆëŠ” íŒŒì¼ ì¸ì§€ í™•ì¸ í•˜ëŠ” flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # ì§€ì›í•˜ëŠ” object classì— ë§ê²Œ ì „ì²˜ë¦¬\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # ë¬¸ì— í•´ë‹¹í•˜ëŠ” idë¡œ class ì¸ë±ìŠ¤\n",
    "            if data[0] == \"0\":\n",
    "                data[0] = str(24)\n",
    "                new_string.append(\" \".join(data))\n",
    "                # ì§€ì›í•˜ëŠ” objectê°€ ë¼ë²¨íŒŒì¼ì— ìˆìœ¼ë©´ flagë¥¼ trueë¡œ ë³€ê²½\n",
    "                exist_flag = True\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆìœ¼ë©´ ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë°ì´í„° íŒŒì¼ì— ì“°ê³  í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ë³µì‚¬\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# ì´ë¯¸ì§€,ë¼ë²¨ ë°ì´í„° ì´ë¦„ ì •ë ¬\n",
    "image_list = sorted([_ for _ in os.listdir(gun1_change_train_image_dir)])\n",
    "label_list = sorted([_ for _ in os.listdir(gun1_change_train_label_dir)])\n",
    "# train, testë¡œ ë‚˜ëˆ„ê¸°\n",
    "train_names, valid_names = train_test_split(image_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "trainLabels_names, validLabels_names = train_test_split(label_list, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train ì´ë¯¸ì§€ë‘ ë¼ë²¨ ê°™ì€ì§€ í™•ì¸\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train ì´ë¯¸ì§€ë‘ ë¼ë²¨ ê°™ì€ì§€ í™•ì¸\n",
    "for image, label in zip(valid_names,validLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  shutil.move(gun1_change_train_image_dir+image,\"../dataset/change_gun_dataset/valid/images/\")\n",
    "  shutil.move(gun1_change_train_label_dir+label,\"../dataset/change_gun_dataset/valid/labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ê³„ë‹¨ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ì›ë˜ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "stair1_origianl_train_label_dir = \"../dataset/stairs_dataset/train/\"\n",
    "stair1_original_train_image_dir = \"../dataset/stairs_dataset/train/\"\n",
    "\n",
    "# ì „ì²˜ë¦¬í•œ coco ë°ì´í„°ì…‹ ë¼ë²¨, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì£¼ì†Œ\n",
    "stair1_change_train_label_dir = \"../dataset/change_stair1_dataset/train/labels/\"\n",
    "stair1_change_train_image_dir = \"../dataset/change_stair1_dataset/train/images/\"\n",
    "\n",
    "stair1_train_label_list = [name for name in os.listdir(stair1_origianl_train_label_dir) if name.split(\".\")[-1] == \"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "for label_name in stair1_train_label_list:\n",
    "\n",
    "    # .txtí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ ì´ë¦„ì„ .jpgí™•ì¥ìë¥¼ ê°–ê³  ìˆëŠ” íŒŒì¼ì´ë¦„ìœ¼ë¡œ ë³€ê²½\n",
    "    image_name = os.path.splitext(label_name)[0] +\".jpg\"\n",
    "\n",
    "    #ì›ë˜ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    original_train_label_path = stair1_origianl_train_label_dir + label_name\n",
    "    original_train_image_path = stair1_original_train_image_dir + image_name\n",
    "\n",
    "    #ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë° ì´ë¯¸ì§€ íŒŒì¼ ì£¼ì†Œ ë³€ìˆ˜\n",
    "    change_train_label_path = stair1_change_train_label_dir + label_name\n",
    "    change_train_image_path = stair1_change_train_image_dir + image_name\n",
    "\n",
    "    with open(original_train_label_path,'r') as file:\n",
    "        # íŒŒì¼ì— ì“¸ ë¬¸ìì—´ ì €ì¥ ë³€ìˆ˜\n",
    "        new_string = []\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆëŠ” íŒŒì¼ ì¸ì§€ í™•ì¸ í•˜ëŠ” flag\n",
    "        exist_flag = False\n",
    "\n",
    "        # ì§€ì›í•˜ëŠ” object classì— ë§ê²Œ ì „ì²˜ë¦¬\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            # ë¬¸ì— í•´ë‹¹í•˜ëŠ” idë¡œ class ì¸ë±ìŠ¤\n",
    "            if data[0] == \"0\":\n",
    "                data[0] = str(25)\n",
    "                new_string.append(\" \".join(data))\n",
    "                # ì§€ì›í•˜ëŠ” objectê°€ ë¼ë²¨íŒŒì¼ì— ìˆìœ¼ë©´ flagë¥¼ trueë¡œ ë³€ê²½\n",
    "                exist_flag = True\n",
    "        # ì§€ì›í•˜ëŠ” objectê°€ ìˆìœ¼ë©´ ì „ì²˜ë¦¬ëœ ë¼ë²¨ ë°ì´í„° íŒŒì¼ì— ì“°ê³  í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ë³µì‚¬\n",
    "        if exist_flag == True:\n",
    "            with open(change_train_label_path,'w') as change_file:\n",
    "                change_file.write(\"\\n\".join(new_string))\n",
    "            shutil.copy(original_train_image_path, change_train_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# ì´ë¯¸ì§€,ë¼ë²¨ ë°ì´í„° ì´ë¦„ ì •ë ¬\n",
    "image_list = sorted([_ for _ in os.listdir(stair1_change_train_image_dir)])\n",
    "label_list = sorted([_ for _ in os.listdir(stair1_change_train_label_dir)])\n",
    "# train, testë¡œ ë‚˜ëˆ„ê¸°\n",
    "train_names, valid_names = train_test_split(image_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "trainLabels_names, validLabels_names = train_test_split(label_list, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train ì´ë¯¸ì§€ë‘ ë¼ë²¨ ê°™ì€ì§€ í™•ì¸\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train ì´ë¯¸ì§€ë‘ ë¼ë²¨ ê°™ì€ì§€ í™•ì¸\n",
    "for image, label in zip(valid_names,validLabels_names):\n",
    "  if image[:-4] != label[:-4]:\n",
    "    print(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for image, label in zip(train_names,trainLabels_names):\n",
    "  shutil.move(stair1_change_train_image_dir+image,\"../dataset/change_stair1_dataset/valid/images/\")\n",
    "  shutil.move(stair1_change_train_label_dir+label,\"../dataset/change_stair1_dataset/valid/labels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO ë ˆíŒŒì§€í† ë¦¬ ë‹¤ìš´ ë° í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Yolov5 github ë ˆí¬ì§€í† ë¦¬ clone\n",
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/src/datasets/code/yolov5-master\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ëª¨ë“ˆ ì„¤ì¹˜\n",
    "!pip install -U -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=./data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 ğŸš€ 2022-6-24 Python-3.8.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 8192MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ğŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=27\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     86304  models.yolo.Detect                      [27, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7092448 parameters, 7092448 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/train/images/000000201706_jpg.rf.7c891d8778f166e1bf2b1fe1b3571d3c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/train/images/000000295376_jpg.rf.ca541ab3589f558ad46ef19d4c8b7995.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/usr/src/datasets/code/yolov5-master/../../dataset/all_dataset/va\u001b[0m\n",
      "Plotting labels to runs/train/exp13/labels.jpg... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.07 anchors/target, 0.953 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found: 25495 of 521754 labels are < 3 pixels in size\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 511487 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6972: 100%|â–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9769 best possible recall, 4.41 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=320, metric_all=0.295/0.685-mean/best, past_thr=0.474-mean: 5,8, 9,13, 11,30, 24,18, 26,41, 61,46, 37,90, 85,121, 163,176\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp13\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     0/299    0.946G   0.07737   0.03698    0.0384        27       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30806      0.544      0.328      0.314      0.184\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     1/299     1.57G   0.07075   0.03729    0.0256         8       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.532      0.336      0.327      0.194\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     2/299     1.57G   0.07195   0.03867   0.02696        19       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.504      0.339      0.316      0.183\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     3/299     1.58G   0.07177   0.03902   0.02706        18       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.496      0.348      0.326      0.193\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     4/299     1.58G   0.07057   0.03873   0.02576        27       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.513      0.364      0.341      0.202\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     5/299     1.58G   0.06982   0.03867   0.02511         6       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.518      0.371      0.354      0.211\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     6/299     1.58G   0.06952   0.03865   0.02462         9       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.519      0.376      0.362      0.216\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     7/299     1.58G    0.0692   0.03855   0.02446        16       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.519      0.383      0.365      0.219\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     8/299     1.58G   0.06904   0.03841   0.02418         3       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.522      0.386      0.369      0.221\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     9/299     1.58G   0.06897   0.03836   0.02413        16       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.517      0.396      0.374      0.224\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    10/299     1.58G   0.06882   0.03837   0.02393        19       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.521      0.394      0.377      0.225\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    11/299     1.58G   0.06871   0.03829   0.02386        29       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.522      0.395      0.379      0.227\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    12/299     1.58G    0.0686   0.03852   0.02371        14       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.505      0.398       0.38      0.228\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    13/299     1.58G   0.06863   0.03833   0.02368         9       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.509        0.4      0.381      0.229\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    14/299     1.58G   0.06839   0.03812   0.02368        35       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.514      0.399      0.382       0.23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    15/299     1.58G   0.06833    0.0381   0.02363        32       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.531      0.393      0.383       0.23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    16/299     1.58G   0.06846   0.03823   0.02352        29       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.531      0.394      0.383       0.23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    17/299     1.58G   0.06828    0.0383   0.02345        17       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.528      0.397      0.384      0.231\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    18/299     1.58G   0.06827   0.03833   0.02334        13       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.531      0.395      0.385      0.232\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    19/299     1.58G   0.06825   0.03823   0.02341        25       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.529      0.396      0.385      0.232\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    20/299     1.58G   0.06829   0.03829   0.02337        40       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.526      0.398      0.386      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    21/299     1.58G   0.06813   0.03818   0.02337        28       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.525        0.4      0.386      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    22/299     1.58G   0.06811   0.03814   0.02328        11       320: 100%|â–ˆâ–ˆâ–ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.512      0.404      0.386      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    23/299     1.58G    0.0681   0.03827    0.0232        34       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.514      0.406      0.387      0.233\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    24/299     1.58G   0.06796    0.0381   0.02322        17       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.521      0.404      0.388      0.235\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    25/299     1.58G   0.06796    0.0379   0.02304        15       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.524      0.405      0.389      0.235\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    26/299     1.58G   0.06794   0.03813   0.02302        23       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.526      0.406       0.39      0.236\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    27/299     1.58G   0.06789   0.03815   0.02311         4       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.522      0.407       0.39      0.236\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    28/299     1.58G   0.06802   0.03831   0.02312        16       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.524      0.405      0.391      0.237\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    29/299     1.58G   0.06782   0.03824   0.02301        33       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819       0.52      0.411      0.392      0.238\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    30/299     1.58G   0.06793   0.03821   0.02295         8       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.532      0.405      0.391      0.238\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    31/299     1.58G   0.06784    0.0381   0.02301        15       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.535      0.406      0.392      0.238\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    32/299     1.58G   0.06777     0.038   0.02282         6       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.534      0.407      0.393      0.239\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    33/299     1.58G   0.06791   0.03822   0.02286        29       320: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       8322      30819      0.534      0.407      0.393      0.239\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "    34/299     1.58G   0.06777   0.03823   0.02304       153       320:  44%|â–ˆâ–ˆâ–ˆ^C\n",
      "    34/299     1.58G   0.06777   0.03823   0.02304       153       320:  44%|â–ˆâ–ˆâ–ˆ\n",
      "Traceback (most recent call last):\n",
      "  File \"./train.py\", line 670, in <module>\n",
      "    main(opt)\n",
      "  File \"./train.py\", line 565, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"./train.py\", line 360, in train\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 363, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "### í›ˆë ¨ì‹œí‚¤ê¸°\n",
    "!python ./train.py --data \"./data.yaml\" --img 320 --epochs 300 --batch 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.9.0 at http://e2c1159c89b8:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir runs/train/exp13/result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST ë°ì´í„° ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "filepath = '../dataset/movie/PARASITE.2019.1080p.FHDRip.H264.AAC-NonDRM.mp4'\n",
    "video = cv2.VideoCapture(filepath) #'' ì‚¬ì´ì— ì‚¬ìš©í•  ë¹„ë””ì˜¤ íŒŒì¼ì˜ ê²½ë¡œ ë° ì´ë¦„ì„ ë„£ì–´ì£¼ë„ë¡ í•¨\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Could not Open :\", filepath)\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 189956\n",
      "width : 1920\n",
      "height : 1080\n",
      "fps : 23.976150195517942\n"
     ]
    }
   ],
   "source": [
    "#ë¶ˆëŸ¬ì˜¨ ë¹„ë””ì˜¤ íŒŒì¼ì˜ ì •ë³´ ì¶œë ¥\n",
    "length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(\"length :\", length)\n",
    "print(\"width :\", width)\n",
    "print(\"height :\", height)\n",
    "print(\"fps :\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frame number : 10\n",
      "Saved frame number : 20\n",
      "Saved frame number : 30\n",
      "Saved frame number : 40\n",
      "Saved frame number : 50\n",
      "Saved frame number : 60\n",
      "Saved frame number : 70\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "filepath = \"../dataset/parasite\"\n",
    "while(video.isOpened()):\n",
    "    ret, image = video.read()\n",
    "    if(int(video.get(1)) % 10 == 0): #ì•ì„œ ë¶ˆëŸ¬ì˜¨ fps ê°’ì„ ì‚¬ìš©í•˜ì—¬ 1ì´ˆë§ˆë‹¤ ì¶”ì¶œ\n",
    "        cv2.imwrite(filepath + \"/frame%d.jpg\" % count, image)\n",
    "        print('Saved frame number :', str(int(video.get(1))))\n",
    "        count += 1\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./yolov5-master/runs/train/exp13/weights/best.pt'], source=../dataset/parasite, data=yolov5-master/data/coco128.yaml, imgsz=[320, 320], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5-master/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ğŸš€ 2022-6-24 Python-3.8.13 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7082944 parameters, 0 gradients, 16.0 GFLOPs\n",
      "image 287/18995 /usr/src/datasets/dataset/parasite/frame10254.jpg: 192x320 2 ì‚¬ëŒs, Done. (0.011s)\n",
      "image 288/18995 /usr/src/datasets/dataset/parasite/frame10255.jpg: 192x320 1 í•¸ë“œí°, 1 ì‚¬ëŒ, Done. (0.008s)\n",
      "image 289/18995 /usr/src/datasets/dataset/parasite/frame10256.jpg: 192x320 1 í•¸ë“œí°, 2 ì‚¬ëŒs, Done. (0.013s)\n",
      "image 290/18995 /usr/src/datasets/dataset/parasite/frame10257.jpg: 192x320 1 í•¸ë“œí°, 2 ì‚¬ëŒs, Done. (0.020s)\n",
      "image 291/18995 /usr/src/datasets/dataset/parasite/frame10258.jpg: 192x320 1 í•¸ë“œí°, 2 ì‚¬ëŒs, Done. (0.010s)\n",
      "image 292/18995 /usr/src/datasets/dataset/parasite/frame10259.jpg: 192x320 1 í•¸ë“œí°, 2 ì‚¬ëŒs, Done. (0.010s)\n",
      "image 293/18995 /usr/src/datasets/dataset/parasite/frame1026.jpg: 192x320 2 ì‚¬ëŒs, Done. (0.010s)\n",
      "image 294/18995 /usr/src/datasets/dataset/parasite/frame10260.jpg: 192x320 1 í•¸ë“œí°, 1 ì‚¬ëŒ, Done. (0.009s)\n",
      "image 295/18995 /usr/src/datasets/dataset/parasite/frame10261.jpg: 192x320 1 ì‚¬ëŒ, Done. (0.009s)\n",
      "image 296/18995 /usr/src/datasets/dataset/parasite/frame10262.jpg: 192x320 1 ì‚¬ëŒ, Done. (0.008s)\n",
      "image 297/18995 /usr/src/datasets/dataset/parasite/frame10263.jpg: 192x320 1 í•¸ë“œí°, 1 ì‚¬ëŒ, Done. (0.008s)\n",
      "image 298/18995 /usr/src/datasets/dataset/parasite/frame10264.jpg: 192x320 1 í•¸ë“œí°, Done. (0.010s)\n",
      "image 299/18995 /usr/src/datasets/dataset/parasite/frame10265.jpg: 192x320 1 í•¸ë“œí°, 1 ì‚¬ëŒ, Done. (0.009s)\n",
      "image 300/18995 /usr/src/datasets/dataset/parasite/frame10266.jpg: 192x320 1 í•¸ë“œí°, 1 ì‚¬ëŒ, Done. (0.009s)\n",
      "image 301/18995 /usr/src/datasets/dataset/parasite/frame10267.jpg: 192x320 1 í•¸ë“œí°, 1 ì‚¬ëŒ, Done. (0.009s)\n",
      "image 302/18995 /usr/src/datasets/dataset/parasite/frame10268.jpg: 192x320 1 í•¸ë“œí°, 1 ì‚¬ëŒ, Done. (0.009s)\n",
      "image 303/18995 /usr/src/datasets/dataset/parasite/frame10269.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.010s)\n",
      "image 304/18995 /usr/src/datasets/dataset/parasite/frame1027.jpg: 192x320 4 ì‚¬ëŒs, Done. (0.009s)\n",
      "image 305/18995 /usr/src/datasets/dataset/parasite/frame10270.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.009s)\n",
      "image 306/18995 /usr/src/datasets/dataset/parasite/frame10271.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.018s)\n",
      "image 307/18995 /usr/src/datasets/dataset/parasite/frame10272.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.010s)\n",
      "image 308/18995 /usr/src/datasets/dataset/parasite/frame10273.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.010s)\n",
      "image 309/18995 /usr/src/datasets/dataset/parasite/frame10274.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.017s)\n",
      "image 310/18995 /usr/src/datasets/dataset/parasite/frame10275.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.010s)\n",
      "image 311/18995 /usr/src/datasets/dataset/parasite/frame10276.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.012s)\n",
      "image 312/18995 /usr/src/datasets/dataset/parasite/frame10277.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.012s)\n",
      "image 313/18995 /usr/src/datasets/dataset/parasite/frame10278.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.013s)\n",
      "image 314/18995 /usr/src/datasets/dataset/parasite/frame10279.jpg: 192x320 1 í•¸ë“œí°, 3 ì‚¬ëŒs, Done. (0.014s)\n",
      "image 315/18995 /usr/src/datasets/dataset/parasite/frame1028.jpg: 192x320 5 ì‚¬ëŒs, Done. (0.013s)\n"
     ]
    }
   ],
   "source": [
    "videoPath = '../dataset/movie/PARASITE.2019.1080p.FHDRip.H264.AAC-NonDRM.mp4'\n",
    "!python ./yolov5-master/detect.py --weights ./yolov5-master/runs/train/exp13/weights/best.pt --source ../dataset/movie/PARASITE.2019.1080p.FHDRip.H264.AAC-NonDRM.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#ì½”ì½”ì˜ì™¸ì˜ ë°ì´í„°ì…‹\n",
    "1. ì´\n",
    "- roboflow pistols dataset : https://public.roboflow.com/object-detection/pistols/1 (Pistols.v1-resize-416x416.yolov5pytorch.zip)\n",
    "2. ê³„ë‹¨\n",
    "- Staircase Dataset : https://data.mendeley.com/datasets/7m97gp4yz9/1 (7m97gp4yz9-1.zip)\n",
    "3. ë¬¸\n",
    "- DoorDetect-Dataset : https://github.com/MiguelARD/DoorDetect-Dataset (DoorDetect-Dataset-master.zip) 1213"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
