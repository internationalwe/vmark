{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 3개 이상 문장 유사도 분석 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰화에서 형태소 분석 시 사용할 모델로 Okt()혹은 Kkma() 중에서 성능이 더 잘 나오는 모델로 선택할 필요성 존재 \n",
    "https://konlpy.org/ko/v0.6.0/morph/\n",
    "- 벡터화는 TfidfVectorizer 사용 \n",
    "- 3개 이상의 문장을 input 받을 때는 cosine_similarity_matrix 사용 \n",
    "- 2개의 문장을 비교할 때는 numpy를 사용하여 cosine similarity 공식 적용 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 코사인 유사도 분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.22576485]\n",
      " [0.22576485 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 문장이 여러개 입력 받는 경우 \n",
    "from konlpy.tag import Kkma \n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_matrix(x_data):\n",
    "\n",
    "    okt = Okt()\n",
    "    for i, document in enumerate(x_data):\n",
    "        nouns = okt.morphs(document)    \n",
    "        x_data[i] = ' '.join(nouns)\n",
    "\n",
    "    # print(x_data)\n",
    "\n",
    "    vect = TfidfVectorizer()\n",
    "    x_data = vect.fit_transform(x_data)\n",
    "    cosine_similarity_matrix = (x_data * x_data.T)\n",
    "\n",
    "    # print(cosine_similarity_matrix.shape)\n",
    "    # print(cosine_similarity_matrix)\n",
    "\n",
    "    return cosine_similarity_matrix.toarray()\n",
    "\n",
    "x_data = np.array(['영희가 사랑하는 강아지 백구를 산책시키고 있다.',\n",
    "        '철수가 사랑하는 소 누렁이를 운동시키고 있다.'])\n",
    "        # '영희와 철수는 소와 강아지를 산책 및 운동시키고 있다.'])\n",
    "        \n",
    "print(cosine_similarity_matrix(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 1대 1 유사도 분석 모델 \n",
    "##### 2.1 코사인 유사도 분석  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2257648460026161\n"
     ]
    }
   ],
   "source": [
    "# 문장이 2개 입력되는 경우\n",
    "from konlpy.tag import Kkma     # 꼬꼬마 사용 \n",
    "from konlpy.tag import Okt\n",
    "from konlpy.utils import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np \n",
    "\n",
    "def cos_similarity(x_data):\n",
    "        \n",
    "        kkma = Kkma()\n",
    "                \n",
    "        doc_nouns_list = []\n",
    "\n",
    "        for data in x_data:\n",
    "                nouns = kkma.morphs(data)\n",
    "                doc_nouns = ''\n",
    "\n",
    "                for noun in nouns:\n",
    "                        doc_nouns+= noun + ' '\n",
    "\n",
    "                doc_nouns_list.append(doc_nouns)\n",
    "\n",
    "        vect = TfidfVectorizer()\n",
    "        x_data = vect.fit_transform(doc_nouns_list)\n",
    "\n",
    "        feature_vect_dense = x_data.todense()      # 벡터화\n",
    "\n",
    "        v1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "        v2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "\n",
    "        dot_product = np.dot(v1, v2)\n",
    "        l2_norm = (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "        return dot_product / l2_norm\n",
    "\n",
    "x_data = ['영희가 사랑하는 강아지 백구를 산책시키고 있다.', '철수가 사랑하는 소 누렁이를 운동시키고 있다.']\n",
    "print(cos_similarity(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "같은 문장으로 유사도 분석을 해 봤을 때 \n",
    "1) Okt() + cosine_similarity_matrix : 유사도 0.30412574\n",
    "2) Okt() + numpy : 유사도 0.3680232087561149\n",
    "3) Kkma() + cosine_similarity_matrix : 0.22576485\n",
    "4) Kkma() + numpy : 유사도 0.2257648460026161\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 레벤슈타인 거리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "#8. Levenschtein distance\n",
    "import numpy as np\n",
    "def leven(text1, text2):\n",
    "    len1 = len(text1) + 1\n",
    "    len2 = len(text2) + 1\n",
    "    sim_array = np.zeros((len1, len2))\n",
    "    sim_array[:,0] = np.linspace(0, len1-1, len1)  # sim_array의 0번째 컬럼의 모든 행에 대해 0부터 len1-1까지 len1등분해서 채우기 \n",
    "    sim_array[0,:] = np.linspace(0, len2-1, len2)\n",
    "    for i in range(1,len1):\n",
    "        for j in range(1,len2):\n",
    "            add_char = sim_array[i-1,j] + 1\n",
    "            sub_char = sim_array[i,j-1] + 1\n",
    "            if text1[i-1] == text2[j-1]:\n",
    "                mod_char = sim_array[i-1,j-1]\n",
    "            else:\n",
    "                mod_char = sim_array[i-1,j-1] + 1\n",
    "            sim_array[i,j] = min([add_char, sub_char, mod_char])\n",
    "    return sim_array[-1,-1]\n",
    "print(leven('데이터마이닝','데이타마닝'))\n",
    "print(leven('영희가 사랑하는 강아지 백구를 산책시키고 있다.', '철수가 사랑하는 소 누렁이를 운동시키고 있다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(a, b):\n",
    "    if a==b: return 0\n",
    "    a_len=len(a)\n",
    "    b_len=len(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 N-gram 유사도 분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram 어휘 벡터 생성 \n",
    "\n",
    "def ngram(s, num):\n",
    "    res = []\n",
    "    slen = len(s)-num+1\n",
    "    for i in range(slen):\n",
    "        ss = s[i:i+num]\n",
    "        res.append(ss)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram: 0.7619047619047619\n",
      "3-gram: 0.45\n",
      "4-gram: 0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "# n-gram 유사도 분석\n",
    "def diff_ngram(sa, sb, num):\n",
    "    a = ngram(sa, num)\n",
    "    b = ngram(sb, num)\n",
    "\n",
    "    r = []\n",
    "    cnt = 0\n",
    "    for i in a :\n",
    "        for j in b:\n",
    "            if i==j:\n",
    "                cnt += 1\n",
    "                r.append(i)\n",
    "    return cnt/len(a)\n",
    "\n",
    "a = \"오늘 강남에서 맛있는 스파게티를 먹었다.\"\n",
    "b = \"강남에서 먹었던 오늘의 스파게티는 맛있었다.\"\n",
    "\n",
    "word2 = diff_ngram(a, b, 2)\n",
    "print(\"2-gram:\", word2)\n",
    "\n",
    "word3 = diff_ngram(a, b, 3)\n",
    "print(\"3-gram:\", word3)\n",
    "\n",
    "word4 = diff_ngram(a, b, 4)\n",
    "print(\"4-gram:\", word4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론 \n",
    "- 코사인 유사도 분석 모델은 유사도가 백분위 숫자로 출력됨\n",
    "- 레벤슈타인 거리는 유사할 수록 낮은 수치가, 유사하지 않을수록 높은 수치로 나타난다. 0~ 범위의 숫자로 값이 출력되며 문장이 길어질수록 점점 수치가 커질 수 있다.\n",
    "- n-gram 유사도의 경우 유사도가 백분위 숫자로 출력된다. 또한 n이 커질수록 유사도가 수치가 점점 낮아진다. => 적절한 n을 선택하는 것이 관건 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8afb11e776545c2f779305d38b35ecf7129a79516cbe52bed3bd66b571a222f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ds_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
